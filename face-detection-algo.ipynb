{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "002563b5",
      "metadata": {
        "id": "002563b5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib.patches import Rectangle\n",
        "from numpy import asarray\n",
        "from mtcnn.mtcnn import MTCNN\n",
        "from PIL import Image\n",
        "import face_recognition\n",
        "import pickle\n",
        "import cv2\n",
        "from pylab import *\n",
        "from scipy.spatial.distance import cosine\n",
        "import imgaug.augmenters as iaa\n",
        "import os\n",
        "from sklearn.preprocessing import normalize"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "244b8174",
      "metadata": {
        "id": "244b8174"
      },
      "source": [
        "#### Initialize paths of folders and threshold value of Cosine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e061fe0f",
      "metadata": {
        "id": "e061fe0f"
      },
      "outputs": [],
      "source": [
        "# Folder of event pictures\n",
        "dossier_event = r\"C:\\Users\\kador\\photos-private\"\n",
        "\n",
        "# Folder of identity pictures (unique)\n",
        "dossier_identity = r\"C:\\Users\\kador\\Downloads\\ML\\photos-perso\"\n",
        "\n",
        "# Initialize the threshold of Cosin Coefficient\n",
        "threshold = 0.95"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cff7905c",
      "metadata": {
        "id": "cff7905c"
      },
      "source": [
        "# 1) Define our functions"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### a) Functions for loading the images, detecting faces, using MTCNN, extracting vectors"
      ],
      "metadata": {
        "id": "mbPvfdmtLhdu"
      },
      "id": "mbPvfdmtLhdu"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4253ea5f",
      "metadata": {
        "id": "4253ea5f"
      },
      "outputs": [],
      "source": [
        "# Load our image\n",
        "def load_image(file_path):\n",
        "    return face_recognition.load_image_file(file_path)\n",
        "\n",
        "# Detect faces from the loaded image\n",
        "def detect_faces(image):\n",
        "    return MTCNN().detect_faces(image)\n",
        "\n",
        "# Calculate cosine similarity and return the result\n",
        "def calculate_cosine_similarity(vector1, vector2):\n",
        "    vector1 = normalize([vector1])[0]\n",
        "    vector2 = normalize([vector2])[0]\n",
        "    return 1 - cosine(vector1, vector2)\n",
        "\n",
        "# Detect faces with MTCNN and extract a list of them\n",
        "def detect_faces_and_extract(photo_path):\n",
        "    photo_load = face_recognition.load_image_file(photo_path)\n",
        "    faces = MTCNN().detect_faces(photo_load)\n",
        "    faces_list = []\n",
        "    # For each face we extract the coordinates of its location\n",
        "    for i, face in enumerate(faces):\n",
        "        x, y, width, height = face['box']\n",
        "        face_image = photo_load[y:y+height, x:x+width]\n",
        "        faces_list.append(face_image)\n",
        "\n",
        "    return photo_load, faces_list\n",
        "\n",
        "# Extract the face vector\n",
        "def extract_face_vector_event(face):\n",
        "    face_rgb = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
        "    face_locations = face_recognition.face_locations(face_rgb)\n",
        "    if face_locations:\n",
        "      # The face vector is obtained with the first element of the function face_encodings()\n",
        "        face_vector = face_recognition.face_encodings(face_rgb, face_locations)[0]\n",
        "        return face_vector\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# Extract the face vector of the identity WITHOUT using data augmentation\n",
        "def extract_face_vector_identity_no_aug(photo_p_load):\n",
        "    # The face vector is obtained with the first element of the function face_encodings()\n",
        "    face_vector_small = face_recognition.face_encodings(photo_p_load)[0]\n",
        "    return face_vector_small"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### b) Function to extract face vector using data augmentation method"
      ],
      "metadata": {
        "id": "nviSyUJwLt_p"
      },
      "id": "nviSyUJwLt_p"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "791ef8ed",
      "metadata": {
        "id": "791ef8ed"
      },
      "outputs": [],
      "source": [
        "# Extract the face vector of the identity by USING DATA AUGMENTATION\n",
        "def extract_face_vector_identity_aug(photo_p_load):\n",
        "\n",
        "    # Définir un séquenceur d'augmentation d'images\n",
        "    seq = iaa.Sequential([\n",
        "        iaa.Fliplr(0.5),\n",
        "        iaa.GaussianBlur((0, 3.0)),\n",
        "        iaa.Affine(rotate=(-45, 45)),\n",
        "        iaa.AdditiveGaussianNoise(scale=(0, 0.1*255))\n",
        "    ], random_order=True)\n",
        "\n",
        "    # Create a list to store augmented images\n",
        "    augmented_images = [photo_p_load]\n",
        "\n",
        "    # Apply augmentation and add augmentation version to the list\n",
        "    for _ in range(8):\n",
        "        augmented_images.append(seq(images=[photo_p_load])[0])\n",
        "\n",
        "    # Create a list to store all face vectors\n",
        "    general_vector = []\n",
        "\n",
        "    # Create an MTCNN detector\n",
        "    detector = MTCNN()\n",
        "\n",
        "    # Process each augmented image\n",
        "    for idx, img in enumerate(augmented_images):\n",
        "\n",
        "        # Detect faces using MTCNN\n",
        "        faces = detector.detect_faces(img)\n",
        "\n",
        "        # Display only the extracted faces\n",
        "        for face in faces:\n",
        "            x, y, width, height = face['box']\n",
        "\n",
        "            # If face is found, extract face vector\n",
        "            face_location = [(y, x + width, y + height, x)]\n",
        "\n",
        "            # Extracting only the face detected with the first element of the function face_encodings\n",
        "            face_vector_small = face_recognition.face_encodings(img, face_location)[0]\n",
        "            general_vector.append(face_vector_small)\n",
        "\n",
        "    # Return the general vector containing all face vectors\n",
        "    # Initialize the weighted average vector\n",
        "    weighted_average_vector = [0] * len(general_vector[0])\n",
        "\n",
        "    # Define weights for each vector\n",
        "    weights = [0.5] + [0.5 / (len(general_vector) - 1)] * (len(general_vector) - 1)\n",
        "\n",
        "    # Calculate the weighted sum\n",
        "    for weight, vector in zip(weights, general_vector):\n",
        "        weighted_average_vector = [w + weight * v for w, v in zip(weighted_average_vector, vector)]\n",
        "\n",
        "    # Normalize the result\n",
        "    total_weight = sum(weights)\n",
        "    weighted_average_vector = [v / total_weight for v in weighted_average_vector]\n",
        "    return weighted_average_vector"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e97bb54",
      "metadata": {
        "id": "3e97bb54"
      },
      "source": [
        "# 2) Predict identities with data augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4697b4e9",
      "metadata": {
        "id": "4697b4e9"
      },
      "source": [
        "### a) Extract faces' vectors on identity pictures (with data augmentation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "116ffebb-c11c-4734-ac87-0060b5590d69",
      "metadata": {
        "scrolled": true,
        "id": "116ffebb-c11c-4734-ac87-0060b5590d69"
      },
      "outputs": [],
      "source": [
        "# Initialize a list to store results\n",
        "results_dict = {}\n",
        "\n",
        "# Loop through all files in the directory\n",
        "for filename in os.listdir(dossier_identity):\n",
        "    # Construct the full path to the image\n",
        "    image_path = os.path.join(dossier_identity, filename)\n",
        "    # Load the image\n",
        "    IMAGE = load_image(image_path)\n",
        "    # Compute the vectors of faces WITH data augmentation (see the function above)\n",
        "    result = extract_face_vector_identity_aug(IMAGE)\n",
        "    # Append the result to the list along with the file name\n",
        "    results_dict[filename] = result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7decf6f7",
      "metadata": {
        "id": "7decf6f7"
      },
      "source": [
        "### b) Loop on every event pictures (explained in our report with a figure)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95bbe81f",
      "metadata": {
        "scrolled": true,
        "id": "95bbe81f"
      },
      "outputs": [],
      "source": [
        "# Association of EVENT and IDENTITY photo initialisation\n",
        "list_association = {}\n",
        "\n",
        "# START OF THE BIG LOOP #\n",
        "##################################\n",
        "# For each photo of the EVENT... #\n",
        "##################################\n",
        "for index_event, photo_event in enumerate(os.listdir(dossier_event)):\n",
        "\n",
        "    photo_event_path = f\"{dossier_event}/{photo_event}\"\n",
        "    photo_event_load, faces_list_event = detect_faces_and_extract(photo_event_path)\n",
        "\n",
        "    ##########################################\n",
        "    # For each FACE detected in the photo...#\n",
        "    ##########################################\n",
        "    for index_face, face in enumerate(faces_list_event):\n",
        "        face_rgb = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Extract face locations from the image\n",
        "        face_locations = face_recognition.face_locations(face_rgb)\n",
        "\n",
        "        # Check if at least one face is detected\n",
        "        if face_locations:\n",
        "            # Extract face encodings (vectors) for the first face\n",
        "            vector_event = face_recognition.face_encodings(face_rgb, face_locations)[0]\n",
        "\n",
        "        list_cosine = []\n",
        "        index_to_photo_identity = {}\n",
        "\n",
        "        ################################\n",
        "        # For each unique IDENTITY ... #\n",
        "        ################################\n",
        "        i=0\n",
        "        for photo_identity, vector_identity in results_dict.items():\n",
        "            index_to_photo_identity[i] = photo_identity\n",
        "\n",
        "            # Compute the cosine similarity between the two vectors\n",
        "            cosine_similarity =  calculate_cosine_similarity(vector_identity, vector_event)\n",
        "            list_cosine.append(cosine_similarity if cosine_similarity >= threshold else 0)\n",
        "            i=i+1\n",
        "        print(f\"\\n>>Face n°{index_face} of photo n°{index_event} done\")\n",
        "        # Only keep the highest cosine coefficient\n",
        "        max_cosine = max(list_cosine)\n",
        "        if max_cosine != 0 :\n",
        "            identity_associated = index_to_photo_identity.get(list_cosine.index(max_cosine))\n",
        "\n",
        "            # Associate the identity to the event photo\n",
        "            list_association[(photo_event, index_face)] = (identity_associated, index_face)\n",
        "            print(f'\\n>>>Association found with max cosine similarity of {round(max_cosine, 8)}!\\nPhoto {photo_event}_N°{index_face} associated to identity {identity_associated}')\n",
        "\n",
        "print(f'\\nSummary of association:\\n{list_association}')\n",
        "# END OF THE BIG LOOP #"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "daa60e84",
      "metadata": {
        "id": "daa60e84"
      },
      "source": [
        "### c) Display all photos' names where the identity is detected"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bf14d97-c445-4158-83c2-dd383afbfe64",
      "metadata": {
        "scrolled": true,
        "id": "4bf14d97-c445-4158-83c2-dd383afbfe64"
      },
      "outputs": [],
      "source": [
        "# Initialize the list\n",
        "data = []\n",
        "photo_identity0 = \"\"\n",
        "photo_event0 = \"\"\n",
        "\n",
        "# For any identity detected on event photos\n",
        "for photo_event, photo_identity in list_association.items():\n",
        "    photo_identity0 = photo_identity[0]\n",
        "    photo_event0 = photo_event[0]\n",
        "\n",
        "    # Add it to our list\n",
        "    data.append(f\"{photo_identity0} {photo_event0}\")\n",
        "\n",
        "# Clean extension names\n",
        "names_list = [item.split(\"g \")[0] for item in data]\n",
        "unique_names = set(names_list)\n",
        "def clean_extension(name):\n",
        "    if name.endswith(\".jp\"):\n",
        "        return name + \"g\"\n",
        "    elif name.endswith(\".jpe\"):\n",
        "        return name + \"g\"\n",
        "    else:\n",
        "        return name\n",
        "\n",
        "# For every identity\n",
        "unique_cleaned_names = set(clean_extension(name) for name in unique_names)\n",
        "for item in data:\n",
        "    # Use the correct index for item\n",
        "    name = item.split(\"g \")[0]\n",
        "    name=name+\"g\"\n",
        "    # Check if the name is in the unique_cleaned_names set\n",
        "    if name in unique_cleaned_names:\n",
        "        link = item.split(\"g \")[1]\n",
        "        # Check if the name already exists in the dictionary\n",
        "        if name not in result_dict:\n",
        "            # If it doesn't exist, create a new entry with the link as a list\n",
        "            result_dict[name] = [link]\n",
        "        else:\n",
        "            # If it already exists, append the link to the existing list\n",
        "            result_dict[name].append(link)\n",
        "\n",
        "# Our result is a dictionnary of key = identity and value = the photos where the identity was detected\n",
        "# This output is the result we need to implement our product onto our app (participants want to get only\n",
        "# the pictures where they appear)\n",
        "unique_result = {key: list(set(value)) for key, value in result_dict.items()}\n",
        "print(unique_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9efcedd",
      "metadata": {
        "id": "b9efcedd"
      },
      "source": [
        "### d) Display the results on the event pictures\n",
        "##### NB : we decided to extract each unique identity to the event picture, so that it is sent uniquely to the client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fee4e49",
      "metadata": {
        "id": "0fee4e49"
      },
      "outputs": [],
      "source": [
        "for photo_event, photo_identity in list_association.items():\n",
        "    big_photo_path = f'{dossier_event}/{photo_event[0]}'\n",
        "    big_photo = face_recognition.load_image_file(big_photo_path)\n",
        "    # Detect faces using MTCNN\n",
        "    big_faces = MTCNN().detect_faces(big_photo)\n",
        "    # Plot the big photo with rectangles around faces\n",
        "    fig, ax = plt.subplots(figsize=(8, 8))\n",
        "    ax.imshow(big_photo)\n",
        "\n",
        "    # Extracted faces from the big photo\n",
        "    big_face_images = []\n",
        "\n",
        "    for i, face in enumerate(big_faces):\n",
        "\n",
        "        x, y, width, height = face['box']\n",
        "\n",
        "        # Extract and store the face image\n",
        "        face_image = big_photo[y:y+height, x:x+width]\n",
        "        big_face_images.append(face_image)\n",
        "\n",
        "        # Draw rectangle around the face\n",
        "        rect = Rectangle((x, y), width, height, fill=False, color='red')\n",
        "        ax.add_patch(rect)\n",
        "\n",
        "        if i == photo_event[1]:\n",
        "            # Draw rectangle around the face\n",
        "            rect = Rectangle((x, y), width, height, fill=False, color='blue')\n",
        "            ax.add_patch(rect)\n",
        "            # Customize appearance of the number\n",
        "            number_text = ax.text(x, y, photo_identity[0], color='blue', fontsize=8, weight='bold')\n",
        "        else:\n",
        "            number_text = ax.text(x, y, \" \", color='red', fontsize=8, weight='bold')\n",
        "            # Draw rectangle around the face\n",
        "            rect = Rectangle((x, y), width, height, fill=False, color='red')\n",
        "            ax.add_patch(rect)\n",
        "\n",
        "    # Display the plot\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92373b8d",
      "metadata": {
        "id": "92373b8d"
      },
      "source": [
        "# 3) Predict identities without data augmentation (testing phase)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "871a18fa",
      "metadata": {
        "id": "871a18fa"
      },
      "source": [
        "### a) Extract faces' vectors on identity pictures (without data augmentation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "190bdd59",
      "metadata": {
        "id": "190bdd59"
      },
      "outputs": [],
      "source": [
        "vectors_no_aug = {}\n",
        "# Loop through all files in the directory\n",
        "for filename in os.listdir(dossier_identity):\n",
        "    # Construct the full path to the image\n",
        "    image_path = os.path.join(dossier_identity, filename)\n",
        "\n",
        "    # Load the image\n",
        "    IMAGE = load_image(image_path)\n",
        "    # Compute faces vectors WITHOUT data augmentation (see function above)\n",
        "    result = extract_face_vector_identity_no_aug(IMAGE)\n",
        "\n",
        "    # Append the result to the list along with the file name\n",
        "    vectors_no_aug[filename] = result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec9a40dc",
      "metadata": {
        "id": "ec9a40dc"
      },
      "source": [
        "### b) Loop on every event pictures\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab00f79b",
      "metadata": {
        "id": "ab00f79b"
      },
      "outputs": [],
      "source": [
        "# Association of EVENT and IDENTITY photo initialisation\n",
        "list_association = {}\n",
        "\n",
        "# START OF THE BIG LOOP #\n",
        "##################################\n",
        "# For each photo of the EVENT... #\n",
        "##################################\n",
        "for index_event, photo_event in enumerate(os.listdir(dossier_event)):\n",
        "\n",
        "    photo_event_path123 = f\"{dossier_event}/{photo_event}\"\n",
        "    photo_event_load, faces_list_event = detect_faces_and_extract(photo_event_path123)\n",
        "\n",
        "    ##########################################\n",
        "    # For each FACE detected in the photo...#\n",
        "    ##########################################\n",
        "    for index_face, face in enumerate(faces_list_event):\n",
        "        face_rgb = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Extract face locations from the image\n",
        "        face_locations = face_recognition.face_locations(face_rgb)\n",
        "\n",
        "        # Check if at least one face is detected\n",
        "        if face_locations:\n",
        "            # Extract face encodings (vectors) for the first face\n",
        "            vector_event = face_recognition.face_encodings(face_rgb, face_locations)[0]\n",
        "\n",
        "        list_cosine = []\n",
        "        index_to_photo_identity = {}\n",
        "\n",
        "        ################################\n",
        "        # For each unique IDENTITY ... #\n",
        "        ################################\n",
        "        i=0\n",
        "        for photo_identity, vector_identity in vectors_no_aug.items():\n",
        "            index_to_photo_identity[i] = photo_identity\n",
        "\n",
        "            # Compute the cosine similarity between the two vectors\n",
        "            cosine_similarity =  calculate_cosine_similarity(vector_identity, vector_event)\n",
        "            list_cosine.append(cosine_similarity if cosine_similarity >= threshold else 0)\n",
        "            i=i+1\n",
        "        print(f\"\\n>>Face n°{index_face} of photo n°{index_event} done\")\n",
        "        # Only keep the highest cosine coefficient\n",
        "        max_cosine = max(list_cosine)\n",
        "        if max_cosine != 0 :\n",
        "            identity_associated = index_to_photo_identity.get(list_cosine.index(max_cosine))\n",
        "\n",
        "            # Associate the identity to the event photo\n",
        "            list_association[(photo_event, index_face)] = (identity_associated, index_face)\n",
        "            print(f'\\n>>>Association found with max cosine similarity of {round(max_cosine, 8)}!\\nPhoto {photo_event}_N°{index_face} associated to identity {identity_associated}')\n",
        "\n",
        "print(f'\\nSummary of association:\\n{list_association}')\n",
        "# END OF THE BIG LOOP #\n",
        "\n",
        "for photo_event, photo_identity in list_association.items():\n",
        "    print(photo_event, photo_identity)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "edc8ab0e",
      "metadata": {
        "id": "edc8ab0e"
      },
      "source": [
        "### c) Display the results on the event pictures\n",
        "##### NB : we decided to extract each unique identity to the event picture, so that it is sent uniquely to the client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61c01a2d",
      "metadata": {
        "scrolled": true,
        "id": "61c01a2d"
      },
      "outputs": [],
      "source": [
        "for photo_event, photo_identity in list_association.items():\n",
        "    big_photo_path = f'{dossier_event}/{photo_event[0]}'\n",
        "    big_photo = face_recognition.load_image_file(big_photo_path)\n",
        "    # Detect faces using MTCNN\n",
        "    big_faces = MTCNN().detect_faces(big_photo)\n",
        "    # Plot the big photo with rectangles around faces\n",
        "    fig, ax = plt.subplots(figsize=(8, 8))\n",
        "    ax.imshow(big_photo)\n",
        "\n",
        "    # Extracted faces from the big photo\n",
        "    big_face_images = []\n",
        "\n",
        "    for i, face in enumerate(big_faces):\n",
        "\n",
        "        x, y, width, height = face['box']\n",
        "\n",
        "        # Extract and store the face image\n",
        "        face_image = big_photo[y:y+height, x:x+width]\n",
        "        big_face_images.append(face_image)\n",
        "\n",
        "        # Draw rectangle around the face\n",
        "        rect = Rectangle((x, y), width, height, fill=False, color='red')\n",
        "        ax.add_patch(rect)\n",
        "\n",
        "        if i == photo_event[1]:\n",
        "            # Draw rectangle around the face\n",
        "            rect = Rectangle((x, y), width, height, fill=False, color='blue')\n",
        "            ax.add_patch(rect)\n",
        "            # Customize appearance of the number\n",
        "            number_text = ax.text(x, y, photo_identity[0], color='blue', fontsize=8, weight='bold')\n",
        "        else:\n",
        "            number_text = ax.text(x, y, \" \", color='red', fontsize=8, weight='bold')\n",
        "            # Draw rectangle around the face\n",
        "            rect = Rectangle((x, y), width, height, fill=False, color='red')\n",
        "            ax.add_patch(rect)\n",
        "\n",
        "    # Display the plot\n",
        "    plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}